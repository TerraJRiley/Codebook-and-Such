{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Latent Dirichlet Allocation\n",
    "Author: Caroline Schmitt, ATL\n",
    "\n",
    "---\n",
    "\n",
    "## What is LDA?\n",
    "\n",
    "Latent Dirichlet allocation is a type of **topic modeling**. A topic model is a statistical model of what themes appear in a collection of documents.\n",
    "\n",
    "Imagine you have a collection of webpages from a pet care website. Each webpage is considered a document. Each document is about different things. One webpage might be about picking a good veterinarian, and another webpage might be about vaccination schedules for your pets.\n",
    "\n",
    "This pet care website might discuss lots of different types of pets. One webpage might be mostly about dogs, but it mentions cats, too. Another webpage might be mostly about reptiles, but also about amphibians and insects.\n",
    "\n",
    "We can think of each type of pet as a potential topic. Some webpages might be 80% about dogs and 20% about cats, and others might be 75% about reptiles, 10% about cats, 10% about dogs, and 5% about insects.\n",
    "\n",
    "LDA infers the underlying (latent!) topics in a collection of documents. It is unsupervised because there is no set `y`. The number of topics to search for is a hyperparameter we can tune, and it's up to the modeler to interpret the results.\n",
    "\n",
    "---\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "LDA pretends each document is generated in the following way:\n",
    "\n",
    "1. Choose N ∼ Poisson(ξ).\n",
    "2. Choose θ ∼ Dir(α).\n",
    "3. For each of the $N$ words $w_n$:\n",
    "    * Choose a topic $z_n$ ∼ Multinomial($\\theta$).\n",
    "    \n",
    "    * Choose a word wn from $p(w_n | z_n ,\\beta)$, a multinomial probability conditioned on the topic $z_n$.\n",
    "\n",
    "(Source: [Latent Dirichlet Allocation](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf).)\n",
    "\n",
    "Or,\n",
    "\n",
    "1. Choose a number of words that the document will have.\n",
    "2. Choose a θ, which is the topic-document distribution. What percentage is the document \"built from\" various topics?\n",
    "3. For each word in the document:\n",
    "    * Choose a topic according to the topic-document distribution.\n",
    "    * Choose a word from the topic, according to the probabilities of words from that topic.\n",
    "    \n",
    "Each topic is a distribution across words. **Every word appears in every topic, but with a different probability.**\n",
    "\n",
    "Since LDA is pretending each document is generated this way, it can reverse-engineer the topics and the word-probabilities per topic.\n",
    "\n",
    "---\n",
    "\n",
    "## Codealong:\n",
    "\n",
    "We're going to topic model on Donald Trump's tweets from 2016.\n",
    "\n",
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @realDonaldTrump: Happy Birthday @DonaldJTr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Birthday @DonaldJTrumpJr!\\nhttps://t.co/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy New Year to all, including to my many en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russians are playing @CNN and @NBCNews for suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Join @AmerIcan32, founded by Hall of Fame lege...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT @realDonaldTrump: Happy Birthday @DonaldJTr...\n",
       "1  Happy Birthday @DonaldJTrumpJr!\\nhttps://t.co/...\n",
       "2  Happy New Year to all, including to my many en...\n",
       "3  Russians are playing @CNN and @NBCNews for suc...\n",
       "4  Join @AmerIcan32, founded by Hall of Fame lege..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/trump_tweets.csv')[['text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv =CountVectorizer(min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(df['text'])\n",
    "text = cv.transform(df['text'])\n",
    "features = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(text.todense(), columns=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an LDA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=5, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=42,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=42) #Arguments go here\n",
    "lda.fit(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43.93793042, 12.86242469,  0.20070232, ...,  1.92425968,\n",
       "         0.2000196 ,  0.20147219],\n",
       "       [ 0.20537154, 49.26501402,  0.20009155, ...,  0.20067156,\n",
       "         1.35695758,  0.20273325],\n",
       "       [ 0.2037069 ,  0.20394793, 11.04003523, ...,  0.20000534,\n",
       "         1.39888098,  0.20020789],\n",
       "       [ 0.20282203,  0.20565637,  0.20017756, ...,  0.20277023,\n",
       "         0.24199685,  8.18655524],\n",
       "       [ 0.20378987, 19.32277882,  0.20010374, ...,  0.20000695,\n",
       "         0.20002324,  0.2018195 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3234\n",
      "3234\n",
      "3234\n",
      "3234\n",
      "3234\n"
     ]
    }
   ],
   "source": [
    "for component in lda.components_:\n",
    "    print(len(component))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDA score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>525.465569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>441.946024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>393.843754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>216.525679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>192.119313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LDA score\n",
       "words              \n",
       "great    525.465569\n",
       "america  441.946024\n",
       "make     393.843754\n",
       "new      216.525679\n",
       "11       192.119313"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'words':features,\n",
    "             'LDA score': lda.components_[4]}).set_index('words').sort_values('LDA score', ascending =False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=8, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=8)\n",
    "lda.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_[0].argsort()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hillary'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[1352] #This new LDA model has it's most important word in that first topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0\n",
      "hillary\n",
      "clinton\n",
      "crooked\n",
      "https\n",
      "debate\n",
      "amp\n",
      "let\n",
      "bernie\n",
      "total\n",
      "jeb\n",
      "\n",
      "\n",
      "Topic  1\n",
      "people\n",
      "obama\n",
      "just\n",
      "good\n",
      "president\n",
      "morning\n",
      "great\n",
      "really\n",
      "florida\n",
      "kasich\n",
      "\n",
      "\n",
      "Topic  2\n",
      "https\n",
      "realdonaldtrump\n",
      "rt\n",
      "trump\n",
      "join\n",
      "amp\n",
      "tomorrow\n",
      "campaign\n",
      "trump2016\n",
      "totally\n",
      "\n",
      "\n",
      "Topic  3\n",
      "trump\n",
      "bad\n",
      "speech\n",
      "https\n",
      "like\n",
      "support\n",
      "beat\n",
      "just\n",
      "marco\n",
      "watch\n",
      "\n",
      "\n",
      "Topic  4\n",
      "new\n",
      "year\n",
      "50\n",
      "members\n",
      "poll\n",
      "great\n",
      "11\n",
      "https\n",
      "big\n",
      "american\n",
      "\n",
      "\n",
      "Topic  5\n",
      "https\n",
      "thank\n",
      "great\n",
      "america\n",
      "make\n",
      "trump2016\n",
      "makeamericagreatagain\n",
      "family\n",
      "live\n",
      "11\n",
      "\n",
      "\n",
      "Topic  6\n",
      "cruz\n",
      "ted\n",
      "people\n",
      "country\n",
      "job\n",
      "look\n",
      "did\n",
      "video\n",
      "realdonaldtrump\n",
      "say\n",
      "\n",
      "\n",
      "Topic  7\n",
      "foxnews\n",
      "trump\n",
      "tonight\n",
      "cnn\n",
      "enjoy\n",
      "rubio\n",
      "donald\n",
      "realdonaldtrump\n",
      "interviewed\n",
      "media\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_words(model, words, num_words=5):\n",
    "    \n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        print('Topic ', ix)\n",
    "        top_words = [words[i] for i in model.components_[ix].argsort()[:-num_words - 1:-1]]\n",
    "        # argsort() says \"wort all components and instead of returing the values, return the indicies\"\n",
    "        print('\\n'.join(top_words))\n",
    "        print('\\n')\n",
    "print_words(lda, features, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at different numbers of topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0\n",
      "just\n",
      "trump\n",
      "win\n",
      "people\n",
      "great\n",
      "\n",
      "\n",
      "Topic  1\n",
      "https\n",
      "thank\n",
      "trump2016\n",
      "makeamericagreatagain\n",
      "great\n",
      "\n",
      "\n",
      "Topic  2\n",
      "great\n",
      "america\n",
      "make\n",
      "https\n",
      "realdonaldtrump\n",
      "\n",
      "\n",
      "Topic  3\n",
      "hillary\n",
      "clinton\n",
      "https\n",
      "crooked\n",
      "people\n",
      "\n",
      "\n",
      "Topic  4\n",
      "cruz\n",
      "cnn\n",
      "ted\n",
      "enjoy\n",
      "tonight\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5)\n",
    "lda.fit(text)\n",
    "print_words(lda, features,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
